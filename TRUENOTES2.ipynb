{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a247bc-2c73-4ba0-8a00-a9d576b1a125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ¼ PANDAS EXAM CHEAT SHEET (FOR BEGINNERS)\n",
    "\n",
    "# -----------------------------------------\n",
    "# 1. IMPORT & LOAD DATA\n",
    "# -----------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('denormalized_li.csv')  # Load CSV file\n",
    "\n",
    "# -----------------------------------------\n",
    "# 2. BASIC DATA INSPECTION\n",
    "# -----------------------------------------\n",
    "\n",
    "df.head()              # View first 5 rows\n",
    "df.tail()              # View last 5 rows\n",
    "df.shape               # Rows and columns (e.g. (110, 11))\n",
    "df.info()              # Column data types and non-null count\n",
    "df.columns             # List all column names\n",
    "\n",
    "# -----------------------------------------\n",
    "# 3. SELECTING COLUMNS\n",
    "# -----------------------------------------\n",
    "\n",
    "df['product_name']                   # Single column as Series\n",
    "df[['product_name']]                 # Single column as DataFrame\n",
    "df[['product_name', 'product_price']]  # Multiple columns\n",
    "\n",
    "# -----------------------------------------\n",
    "# 4. SLICING ROWS AND COLUMNS\n",
    "# -----------------------------------------\n",
    "\n",
    "row_slice = [1, 2, 3]\n",
    "col_slice = ['product_name', 'product_price']\n",
    "df.loc[row_slice, col_slice]        # Select specific rows and columns\n",
    "\n",
    "df.loc[[1, 2, 3], ['product_name', 'product_price']]  # Manual version\n",
    "\n",
    "df.loc[:, ['transaction_created_at']]  # All rows, specific column\n",
    "\n",
    "# -----------------------------------------\n",
    "# 5. FILTERING ROWS\n",
    "# -----------------------------------------\n",
    "\n",
    "df[df['product_name'] == 'Tablet']  # Show rows where product_name is Tablet\n",
    "\n",
    "# -----------------------------------------\n",
    "# 6. SUM / TOTALS\n",
    "# -----------------------------------------\n",
    "\n",
    "df['line_item_quantity'].sum()     # Total quantity sold\n",
    "df[df['product_name'] == 'Tablet']['line_item_quantity'].sum()  # Total tablets sold\n",
    "\n",
    "# -----------------------------------------\n",
    "# 7. AGGREGATION FUNCTIONS\n",
    "# -----------------------------------------\n",
    "\n",
    "df['line_item_quantity'].mean()    # Average quantity\n",
    "df['line_item_quantity'].min()     # Minimum quantity\n",
    "df['line_item_quantity'].max()     # Maximum quantity\n",
    "\n",
    "# Custom aggregation (range)\n",
    "def my_range(x):\n",
    "    return x.max() - x.min()\n",
    "\n",
    "df['line_item_quantity'].agg(my_range)\n",
    "\n",
    "# -----------------------------------------\n",
    "# 8. GROUPING DATA\n",
    "# -----------------------------------------\n",
    "\n",
    "df.groupby('transaction_id')['line_item_quantity'].sum()  # Quantity per transaction\n",
    "\n",
    "# -----------------------------------------\n",
    "# 9. HANDLING MISSING VALUES\n",
    "# -----------------------------------------\n",
    "\n",
    "df = df[df['transaction_id'].notnull()]  # Remove rows where transaction_id is NaN\n",
    "\n",
    "# -----------------------------------------\n",
    "# 10. TYPE CONVERSION\n",
    "# -----------------------------------------\n",
    "\n",
    "df['transaction_id'] = df['transaction_id'].astype(int).astype(str)  # Convert to int then str\n",
    "df['transaction_id'] = 'tx-' + df['transaction_id']  # Add prefix like tx-8, tx-28\n",
    "\n",
    "# -----------------------------------------\n",
    "# 11. USING NUMPY\n",
    "# -----------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "np.int64(329)  # Convert value to NumPy int64\n",
    "\n",
    "# -----------------------------------------\n",
    "# 12. DATE COLUMNS\n",
    "# -----------------------------------------\n",
    "\n",
    "df.loc[:, ['transaction_created_at']]  # Show all rows for transaction_created_at\n",
    "\n",
    "# -----------------------------------------\n",
    "# ðŸ”‘ QUICK SYNTAX REFERENCE\n",
    "# -----------------------------------------\n",
    "\n",
    "# Select columns:         df['col'], df[['col1', 'col2']]\n",
    "# Slice rows/cols:        df.loc[rows, cols]\n",
    "# Filter by condition:    df[df['col'] == value]\n",
    "# Sum / Mean:             df['col'].sum(), df['col'].mean()\n",
    "# Group and aggregate:    df.groupby('col')['other_col'].sum()\n",
    "# Convert types:          df['col'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81155c20-c002-44da-91a8-b72ae785ac8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ¼ PANDAS EXAM CHEAT SHEET (FOR BEGINNERS)\n",
    "\n",
    "# -----------------------------------------\n",
    "# 1. IMPORT & LOAD DATA\n",
    "# -----------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('denormalized_li.csv')  # Load CSV file\n",
    "\n",
    "# -----------------------------------------\n",
    "# 2. BASIC DATA INSPECTION\n",
    "# -----------------------------------------\n",
    "\n",
    "df.head()              # View first 5 rows\n",
    "df.tail()              # View last 5 rows\n",
    "df.shape               # Rows and columns (e.g. (110, 11))\n",
    "df.info()              # Column data types and non-null count\n",
    "df.columns             # List all column names\n",
    "\n",
    "# -----------------------------------------\n",
    "# 3. SELECTING COLUMNS\n",
    "# -----------------------------------------\n",
    "\n",
    "df['product_name']                   # Single column as Series\n",
    "df[['product_name']]                 # Single column as DataFrame\n",
    "df[['product_name', 'product_price']]  # Multiple columns\n",
    "\n",
    "# -----------------------------------------\n",
    "# 4. SLICING ROWS AND COLUMNS\n",
    "# -----------------------------------------\n",
    "\n",
    "row_slice = [1, 2, 3]\n",
    "col_slice = ['product_name', 'product_price']\n",
    "df.loc[row_slice, col_slice]        # Select specific rows and columns\n",
    "\n",
    "df.loc[[1, 2, 3], ['product_name', 'product_price']]  # Manual version\n",
    "\n",
    "df.loc[:, ['transaction_created_at']]  # All rows, specific column\n",
    "\n",
    "# -----------------------------------------\n",
    "# 5. FILTERING ROWS\n",
    "# -----------------------------------------\n",
    "\n",
    "df[df['product_name'] == 'Tablet']  # Show rows where product_name is Tablet\n",
    "\n",
    "# -----------------------------------------\n",
    "# 6. SUM / TOTALS\n",
    "# -----------------------------------------\n",
    "\n",
    "df['line_item_quantity'].sum()     # Total quantity sold\n",
    "df[df['product_name'] == 'Tablet']['line_item_quantity'].sum()  # Total tablets sold\n",
    "\n",
    "# -----------------------------------------\n",
    "# 7. AGGREGATION FUNCTIONS\n",
    "# -----------------------------------------\n",
    "\n",
    "df['line_item_quantity'].mean()    # Average quantity\n",
    "df['line_item_quantity'].min()     # Minimum quantity\n",
    "df['line_item_quantity'].max()     # Maximum quantity\n",
    "\n",
    "# Custom aggregation (range)\n",
    "def my_range(x):\n",
    "    return x.max() - x.min()\n",
    "\n",
    "df['line_item_quantity'].agg(my_range)\n",
    "\n",
    "# -----------------------------------------\n",
    "# 8. GROUPING DATA\n",
    "# -----------------------------------------\n",
    "\n",
    "df.groupby('transaction_id')['line_item_quantity'].sum()  # Quantity per transaction\n",
    "\n",
    "# -----------------------------------------\n",
    "# 9. HANDLING MISSING VALUES\n",
    "# -----------------------------------------\n",
    "\n",
    "df = df[df['transaction_id'].notnull()]  # Remove rows where transaction_id is NaN\n",
    "\n",
    "# -----------------------------------------\n",
    "# 10. TYPE CONVERSION\n",
    "# -----------------------------------------\n",
    "\n",
    "df['transaction_id'] = df['transaction_id'].astype(int).astype(str)  # Convert to int then str\n",
    "df['transaction_id'] = 'tx-' + df['transaction_id']  # Add prefix like tx-8, tx-28\n",
    "\n",
    "# -----------------------------------------\n",
    "# 11. USING NUMPY\n",
    "# -----------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "np.int64(329)  # Convert value to NumPy int64\n",
    "\n",
    "# -----------------------------------------\n",
    "# 12. DATE COLUMNS\n",
    "# -----------------------------------------\n",
    "\n",
    "df.loc[:, ['transaction_created_at']]  # Show all rows for transaction_created_at\n",
    "\n",
    "# -----------------------------------------\n",
    "# ðŸ”‘ QUICK SYNTAX REFERENCE\n",
    "# -----------------------------------------\n",
    "\n",
    "# Select columns:         df['col'], df[['col1', 'col2']]\n",
    "# Slice rows/cols:        df.loc[rows, cols]\n",
    "# Filter by condition:    df[df['col'] == value]\n",
    "# Sum / Mean:             df['col'].sum(), df['col'].mean()\n",
    "# Group and aggregate:    df.groupby('col')['other_col'].sum()\n",
    "# Convert types:          df['col'].astype(str)\n",
    "âœ… You can paste this directly into a .txt, .docx, or .ipynb file for easy reference during your exam. Let me know if you want it in PDF or Google Docs format too!\n",
    "\n",
    "\n",
    "2/2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "You said:\n",
    "perfect. now make it a little bit more advanced because i dont think the questions will be that easy since i have open notes\n",
    "\n",
    "\n",
    "ChatGPT said:\n",
    "Absolutely â€” here's a slightly more advanced version of the cheat sheet, still beginner-friendly but with added tools and tricks that will impress your prof and help you handle open-notes exam questions confidently.\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "# ðŸ¼ PANDAS EXAM CHEAT SHEET (BEGINNER â†’ INTERMEDIATE)\n",
    "\n",
    "# =========================================\n",
    "# 1. IMPORT LIBRARIES & LOAD CSV\n",
    "# =========================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('denormalized_li.csv')\n",
    "\n",
    "# =========================================\n",
    "# 2. QUICK LOOK AT DATA\n",
    "# =========================================\n",
    "\n",
    "df.head()                 # Preview first 5 rows\n",
    "df.tail()                 # Preview last 5 rows\n",
    "df.shape                  # (rows, columns)\n",
    "df.columns                # List of column names\n",
    "df.info()                 # Data types + non-null counts\n",
    "df.describe()             # Quick stats for numeric columns\n",
    "df.sample(5)              # Random 5 rows\n",
    "\n",
    "# =========================================\n",
    "# 3. COLUMN & ROW SELECTION\n",
    "# =========================================\n",
    "\n",
    "df['col']                          # Series\n",
    "df[['col']]                        # DataFrame with 1 column\n",
    "df[['col1', 'col2']]               # Multiple columns\n",
    "\n",
    "df.loc[0:5, ['col1', 'col2']]      # Row & column slice using labels\n",
    "df.iloc[0:5, 1:3]                  # Row & column slice by position\n",
    "\n",
    "# Select using variables\n",
    "col_slice = ['product_name', 'product_price']\n",
    "row_slice = [1, 2, 3]\n",
    "df.loc[row_slice, col_slice]\n",
    "\n",
    "# =========================================\n",
    "# 4. FILTERING / CONDITIONAL SELECTION\n",
    "# =========================================\n",
    "\n",
    "df[df['product_name'] == 'Tablet']\n",
    "df[df['product_price'] > 1000]\n",
    "df[(df['product_name'] == 'Blender') & (df['product_price'] < 50)]\n",
    "\n",
    "# .isin() for multiple values\n",
    "df[df['product_name'].isin(['Tablet', 'Laptop'])]\n",
    "\n",
    "# Filter non-missing\n",
    "df[df['transaction_id'].notna()]\n",
    "\n",
    "# =========================================\n",
    "# 5. SORTING\n",
    "# =========================================\n",
    "\n",
    "df.sort_values('product_price', ascending=False)\n",
    "df.sort_values(by=['product_name', 'product_price'])\n",
    "\n",
    "# =========================================\n",
    "# 6. AGGREGATION & GROUPING\n",
    "# =========================================\n",
    "\n",
    "df['line_item_quantity'].sum()\n",
    "df['line_item_quantity'].mean()\n",
    "df['line_item_quantity'].agg(['min', 'max', 'sum', 'mean'])\n",
    "\n",
    "# GroupBy\n",
    "df.groupby('product_name')['line_item_quantity'].sum()\n",
    "df.groupby('transaction_id')[['line_item_quantity']].mean()\n",
    "df.groupby(['product_name', 'product_brand'])[['line_item_quantity']].sum()\n",
    "\n",
    "# Custom function with .agg()\n",
    "def my_range(x):\n",
    "    return x.max() - x.min()\n",
    "\n",
    "df['line_item_quantity'].agg(my_range)\n",
    "df.groupby('product_name')['line_item_quantity'].agg(my_range)\n",
    "\n",
    "# =========================================\n",
    "# 7. HANDLING MISSING DATA\n",
    "# =========================================\n",
    "\n",
    "df.isnull().sum()                     # Count missing per column\n",
    "df[df['transaction_created_at'].isnull()]  # Show rows with missing timestamps\n",
    "df.dropna(subset=['transaction_created_at'], inplace=True)\n",
    "\n",
    "# =========================================\n",
    "# 8. DATA TYPE CONVERSIONS\n",
    "# =========================================\n",
    "\n",
    "df['transaction_id'] = df['transaction_id'].astype('Int64')      # Safe int (allows NaN)\n",
    "df['transaction_id'] = df['transaction_id'].astype(int).astype(str)\n",
    "df['transaction_id'] = 'tx-' + df['transaction_id']              # Add prefix\n",
    "\n",
    "# Convert datetime\n",
    "df['transaction_created_at'] = pd.to_datetime(df['transaction_created_at'])\n",
    "\n",
    "# Extract date parts\n",
    "df['transaction_created_at'].dt.date\n",
    "df['transaction_created_at'].dt.year\n",
    "\n",
    "# =========================================\n",
    "# 9. STRING OPERATIONS\n",
    "# =========================================\n",
    "\n",
    "df['product_name'].str.upper()\n",
    "df['product_name'].str.contains('blender', case=False)\n",
    "df['product_brand'].str.strip()\n",
    "\n",
    "# =========================================\n",
    "# 10. VALUE COUNTS & UNIQUES\n",
    "# =========================================\n",
    "\n",
    "df['product_name'].value_counts()\n",
    "df['product_name'].nunique()\n",
    "df['product_name'].unique()\n",
    "\n",
    "# =========================================\n",
    "# 11. ADVANCED FILTERING / MASKING\n",
    "# =========================================\n",
    "\n",
    "# All rows where 'product_price' is above average\n",
    "df[df['product_price'] > df['product_price'].mean()]\n",
    "\n",
    "# First occurrence per product\n",
    "df.drop_duplicates(subset='product_name')\n",
    "\n",
    "# =========================================\n",
    "# 12. EXPORTING RESULTS\n",
    "# =========================================\n",
    "\n",
    "df.to_csv('output.csv', index=False)\n",
    "\n",
    "# =========================================\n",
    "# âœ… QUICK SYNTAX SUMMARY\n",
    "# =========================================\n",
    "\n",
    "# df['col']                      â†’ select column (Series)\n",
    "# df[['col1', 'col2']]           â†’ select multiple columns (DataFrame)\n",
    "# df.loc[rows, cols]             â†’ label-based slicing\n",
    "# df.iloc[rows, cols]            â†’ position-based slicing\n",
    "# df[df['col'] == val]           â†’ filter by condition\n",
    "# df.groupby('col')['val'].sum() â†’ group and aggregate\n",
    "# df['col'].astype(type)         â†’ convert data type\n",
    "# df['col'].str.upper()          â†’ string operation\n",
    "# df.to_csv(...)                 â†’ export CSV\n",
    "\n",
    "# Bonus:\n",
    "# df.query('col > 100')          â†’ SQL-style filtering (optional)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
